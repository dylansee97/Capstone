{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "73JdMPfGniiB",
    "outputId": "7a920984-5a1c-4124-d510-2cbf5fce715a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr. -> PROPN\n",
      "Tan -> PROPN\n",
      "said -> VERB\n",
      "hi -> INTJ\n",
      ". -> PUNCT\n"
     ]
    }
   ],
   "source": [
    "# POS Tagging\n",
    "import spacy\n",
    "\n",
    "# load english language model\n",
    "nlp = spacy.load('en_core_web_sm',disable=['ner','textcat'])\n",
    "\n",
    "text = \"Mr. Tan said hi.\"\n",
    "\n",
    "# create spacy \n",
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text,'->',token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/dylan/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# parse article and get the entities, counts\n",
    "\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from newspaper import Article\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "\n",
    "def article_extraction(link):\n",
    "    article = Article(link)\n",
    "    article.download()\n",
    "    article.parse()\n",
    "    return article.text\n",
    "\n",
    "def parse(link):\n",
    "    doc = nlp(article_extraction(link))\n",
    "    print([(X.text, X.label_) for X in doc.ents])\n",
    "    labels = [x.label_ for x in doc.ents]\n",
    "    print(Counter(labels))\n",
    "    items = [x.text for x in doc.ents]\n",
    "    print(Counter(items).most_common(10))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "leeyanru = \"https://www.straitstimes.com/singapore/courts-crime/smu-molestation-trial-accused-says-victim-was-fine-with-his-advances\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = article_extraction(leeyanru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x8V3Y6es6nFb",
    "outputId": "f44f7424-c438-4eab-a086-a965f4ec82ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('politic.a.01'), Synset('politic.s.02')]\n",
      "Synset('politic.a.01')\n",
      "Synset('cookbook.n.01')\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# using wordnet for name matching\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from itertools import product\n",
    "\n",
    "print(wordnet.synsets('politic'))\n",
    "\n",
    "wordx, wordy = \"politic\",\"politic\"\n",
    "sem1, sem2 = wn.synsets(wordx)[0], wn.synsets(wordy)[0]\n",
    "print(sem1)\n",
    "\n",
    "\n",
    "\n",
    "cb = wordnet.synset('cookbook.n.01')\n",
    "print(cb)\n",
    "ib = wordnet.synset('instruction_book.n.01')\n",
    "print(cb.wup_similarity(sem1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-PZMfy93UvZQ"
   },
   "outputs": [],
   "source": [
    "# exploring model training to classify types of articles (naive bayes)\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "train = fetch_20newsgroups(subset='train')\n",
    "test = fetch_20newsgroups(subset='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KucbTiSvSlcy",
    "outputId": "b2f79b42-3de0-47d0-9629-cfee0091cee0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 130107)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5rVSBMTJWj-p",
    "outputId": "ab795f94-00e7-42af-e73d-cc6915db82ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 130107)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "br7OKn-YWuba"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2apZcm3nXssj"
   },
   "outputs": [],
   "source": [
    ">>> from sklearn.pipeline import Pipeline\n",
    ">>> text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "...                      ('tfidf', TfidfTransformer()),\n",
    "...                      ('clf', MultinomialNB()),\n",
    "... ])\n",
    "model = text_clf.fit(twenty_train.data, twenty_train.target)\n",
    "\n",
    "labels = model.predict(test.data)\n",
    "\n",
    "def predict_cat(s, train = train, model = model):\n",
    "  pred = model.predict([s])\n",
    "  return train.target_names[pred[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "6LMWz2YZX7I4",
    "outputId": "fd67b0dd-1860-44a2-d5f7-6dbba60cb50d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'sci.crypt'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from newspaper import Article\n",
    "\n",
    "def article_extraction(link):\n",
    "    article = Article(link)\n",
    "    article.download()\n",
    "    article.parse()\n",
    "    return article.text\n",
    "\n",
    "lst = []\n",
    "link = \"https://www.straitstimes.com/singapore/courts-crime/20-more-charges-for-spore-businessman-ng-yu-zhi-over-alleged-12-billion-fraud\"\n",
    "doc = article_extraction(link)\n",
    "predict_cat(doc)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Test2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
