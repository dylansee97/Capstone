{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t_QhRzNVkNDH",
    "outputId": "e7314c3f-33d6-4989-ed22-a4967fc01605"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.1.2-cp38-cp38-macosx_10_9_x86_64.whl (6.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.0 MB 5.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
      "  Downloading pydantic-1.8.2-cp38-cp38-macosx_10_9_x86_64.whl (2.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.6 MB 38.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pathy>=0.3.5\n",
      "  Downloading pathy-0.6.0-py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 4.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.5-cp38-cp38-macosx_10_9_x86_64.whl (31 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.5-cp38-cp38-macosx_10_9_x86_64.whl (105 kB)\n",
      "\u001b[K     |████████████████████████████████| 105 kB 15.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting catalogue<2.1.0,>=2.0.4\n",
      "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from spacy) (20.4)\n",
      "Collecting thinc<8.1.0,>=8.0.8\n",
      "  Downloading thinc-8.0.10-cp38-cp38-macosx_10_9_x86_64.whl (607 kB)\n",
      "\u001b[K     |████████████████████████████████| 607 kB 29.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting blis<0.8.0,>=0.4.0\n",
      "  Downloading blis-0.7.4-cp38-cp38-macosx_10_9_x86_64.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 13.6 MB/s eta 0:00:01     |███████▎                        | 1.3 MB 13.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting spacy-legacy<3.1.0,>=3.0.7\n",
      "  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from spacy) (4.47.0)\n",
      "Collecting srsly<3.0.0,>=2.4.1\n",
      "  Downloading srsly-2.4.1-cp38-cp38-macosx_10_9_x86_64.whl (450 kB)\n",
      "\u001b[K     |████████████████████████████████| 450 kB 13.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wasabi<1.1.0,>=0.8.1\n",
      "  Downloading wasabi-0.8.2-py3-none-any.whl (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.5-cp38-cp38-macosx_10_9_x86_64.whl (18 kB)\n",
      "Requirement already satisfied: jinja2 in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from spacy) (2.11.2)\n",
      "Collecting typer<0.4.0,>=0.3.0\n",
      "  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: setuptools in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from spacy) (49.2.0.post20200714)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from spacy) (2.24.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from spacy) (1.18.5)\n",
      "Collecting typing-extensions>=3.7.4.3\n",
      "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from pathy>=0.3.5->spacy) (5.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: six in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy) (1.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from jinja2->spacy) (1.1.1)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
      "Installing collected packages: typing-extensions, pydantic, typer, pathy, cymem, murmurhash, preshed, catalogue, srsly, blis, wasabi, thinc, spacy-legacy, spacy\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.7.4.2\n",
      "    Uninstalling typing-extensions-3.7.4.2:\n",
      "      Successfully uninstalled typing-extensions-3.7.4.2\n",
      "Successfully installed blis-0.7.4 catalogue-2.0.6 cymem-2.0.5 murmurhash-1.0.5 pathy-0.6.0 preshed-3.0.5 pydantic-1.8.2 spacy-3.1.2 spacy-legacy-3.0.8 srsly-2.4.1 thinc-8.0.10 typer-0.3.2 typing-extensions-3.10.0.2 wasabi-0.8.2\n",
      "Requirement already satisfied: newspaper3k in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (0.2.8)\n",
      "Requirement already satisfied: nltk>=3.2.1 in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from newspaper3k) (3.6.2)\n",
      "Requirement already satisfied: tinysegmenter==0.3 in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from newspaper3k) (0.3)\n",
      "Requirement already satisfied: PyYAML>=3.11 in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from newspaper3k) (5.3.1)\n",
      "Requirement already satisfied: requests>=2.10.0 in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from newspaper3k) (2.24.0)\n",
      "Requirement already satisfied: cssselect>=0.9.2 in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from newspaper3k) (1.1.0)\n",
      "Requirement already satisfied: Pillow>=3.3.0 in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from newspaper3k) (7.2.0)\n",
      "Requirement already satisfied: tldextract>=2.0.1 in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from newspaper3k) (3.1.0)\n",
      "Requirement already satisfied: lxml>=3.6.0 in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from newspaper3k) (4.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from newspaper3k) (2.8.1)\n",
      "Requirement already satisfied: jieba3k>=0.35.1 in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from newspaper3k) (0.35.1)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from newspaper3k) (4.9.1)\n",
      "Requirement already satisfied: feedparser>=5.2.1 in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from newspaper3k) (6.0.8)\n",
      "Requirement already satisfied: feedfinder2>=0.0.4 in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from newspaper3k) (0.0.4)\n",
      "Requirement already satisfied: tqdm in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from nltk>=3.2.1->newspaper3k) (4.47.0)\n",
      "Requirement already satisfied: regex in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from nltk>=3.2.1->newspaper3k) (2020.6.8)\n",
      "Requirement already satisfied: joblib in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from nltk>=3.2.1->newspaper3k) (0.16.0)\n",
      "Requirement already satisfied: click in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from nltk>=3.2.1->newspaper3k) (7.1.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.10.0->newspaper3k) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.10.0->newspaper3k) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.10.0->newspaper3k) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.10.0->newspaper3k) (2020.6.20)\n",
      "Requirement already satisfied: requests-file>=1.4 in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from tldextract>=2.0.1->newspaper3k) (1.5.1)\n",
      "Requirement already satisfied: filelock>=3.0.8 in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from tldextract>=2.0.1->newspaper3k) (3.0.12)\n",
      "Requirement already satisfied: six>=1.5 in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.5.3->newspaper3k) (1.15.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.0.1)\n",
      "Requirement already satisfied: sgmllib3k in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from feedparser>=5.2.1->newspaper3k) (1.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fuzzywuzzy\n",
      "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
      "Installing collected packages: fuzzywuzzy\n",
      "Successfully installed fuzzywuzzy-0.18.0\n",
      "Collecting python-Levenshtein\n",
      "  Downloading python-Levenshtein-0.12.2.tar.gz (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 4.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /Users/dylan/opt/anaconda3/lib/python3.8/site-packages (from python-Levenshtein) (49.2.0.post20200714)\n",
      "Building wheels for collected packages: python-Levenshtein\n",
      "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp38-cp38-macosx_10_9_x86_64.whl size=80460 sha256=93a78e6c46e1e7b055d4a6fd1d9f0d018fe2a11c73e89864527a1241d4823ee0\n",
      "  Stored in directory: /Users/dylan/Library/Caches/pip/wheels/d7/0c/76/042b46eb0df65c3ccd0338f791210c55ab79d209bcc269e2c7\n",
      "Successfully built python-Levenshtein\n",
      "Installing collected packages: python-Levenshtein\n",
      "Successfully installed python-Levenshtein-0.12.2\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!pip install newspaper3k\n",
    "!pip install fuzzywuzzy\n",
    "!pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BJygRlWBhQZr",
    "outputId": "f6747acb-26a7-4c10-838c-c588fcc1f368"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/dylan/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# parse article and get the entities, counts\n",
    "\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from newspaper import Article\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "\n",
    "def article_extraction(link):\n",
    "    article = Article(link)\n",
    "    article.download()\n",
    "    article.parse()\n",
    "    return article.text\n",
    "\n",
    "def parse(link):\n",
    "    doc = nlp(article_extraction(link))\n",
    "    print([(X.text, X.label_) for X in doc.ents])\n",
    "    labels = [x.label_ for x in doc.ents]\n",
    "    print(Counter(labels))\n",
    "    items = [x.text for x in doc.ents]\n",
    "    print(Counter(items).most_common(10))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OD-zpIDxZPAr",
    "outputId": "dd623a8b-3d1f-4032-f1b3-a8147086f432"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "# basic fuzzy score function\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "def fuzzy_name_score(n1, n2):\n",
    "  return fuzz.partial_ratio(n1, n2)\n",
    "\n",
    "print(fuzz.partial_ratio(\"shaun\", \"sean\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "N63F0-3VTIt0"
   },
   "outputs": [],
   "source": [
    "# not finished\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# def test(link):\n",
    "#   lst = []\n",
    "#   doc = article_extraction(link)\n",
    "#   lst.append(doc)\n",
    "#   count_vect = CountVectorizer()\n",
    "#   X_train_counts = count_vect.fit_transform(lst)\n",
    "#   print(X_train_counts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IqOWsnatTFAS",
    "outputId": "6d1fff7b-19c8-4176-a16a-e5c9ee79b4b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "[('SINGAPORE', 'GPE'), ('The Singapore Management University', 'ORG'), ('SMU', 'ORG'), ('overnight', 'TIME'), ('Monday', 'DATE'), ('Lee Yan Ru', 'PERSON'), ('24', 'DATE'), ('the early hours', 'TIME'), ('22', 'DATE'), ('SMU', 'ORG'), ('Lee', 'PERSON'), ('Josephine Chee', 'PERSON'), ('Rajah & Tann', 'ORG'), ('the night', 'TIME'), ('Lee', 'PERSON'), ('Lee', 'PERSON'), ('SMU', 'ORG'), ('Lee', 'PERSON'), ('overnight', 'TIME'), ('Lee', 'PERSON'), ('the night progress(ed', 'TIME'), ('one', 'CARDINAL'), ('Lee', 'PERSON'), ('Lee', 'PERSON'), ('under 10 seconds', 'TIME'), ('Lee', 'PERSON'), ('that morning', 'TIME'), ('Tuesday', 'DATE'), ('Lee', 'PERSON'), ('Lee', 'PERSON'), ('up to two years', 'DATE')]\n",
      "Counter({'PERSON': 12, 'TIME': 7, 'ORG': 5, 'DATE': 5, 'GPE': 1, 'CARDINAL': 1})\n",
      "[('Lee', 10), ('SMU', 3), ('overnight', 2), ('SINGAPORE', 1), ('The Singapore Management University', 1), ('Monday', 1), ('Lee Yan Ru', 1), ('24', 1), ('the early hours', 1), ('22', 1)]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Driver code\n",
    "if __name__ == \"__main__\" :\n",
    "    trump =\"https://www.express.co.uk/news/world/1483580/donald-trump-2024-republicans-ex-potus-anthony-sabatini-white-house-desantis-world-ont\"\n",
    "    leeyanru = \"https://www.straitstimes.com/singapore/courts-crime/smu-molestation-trial-accused-says-victim-was-fine-with-his-advances\"\n",
    "    ngyuzhi = \"https://www.straitstimes.com/singapore/courts-crime/20-more-charges-for-spore-businessman-ng-yu-zhi-over-alleged-12-billion-fraud\"\n",
    "    #parse(trump)\n",
    "    print(\"\\n\")\n",
    "    #parse(najib)\n",
    "    print(\"\\n\")\n",
    "    parse(leeyanru)\n",
    "    print(\"\\n\")\n",
    "    # test(trump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date analysis to extract age \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dylan/opt/anaconda3/lib/python3.8/site-packages/allennlp/tango/__init__.py:17: UserWarning: AllenNLP Tango is an experimental API and parts of it might change or disappear every time we release a new version.\n",
      "  warnings.warn(\n",
      "2021-09-08 20:25:04,156 - INFO - allennlp.common.file_utils - https://s3-us-west-2.amazonaws.com/allennlp/models/fine-grained-ner-model-elmo-2018.12.21.tar.gz not found in cache, downloading to /Users/dylan/.allennlp/cache/a13840d22e17d9a789d2d5e4ec9a760e1051bd6311ee726660cbecdcdb2906f4.a306d04cf71c2432c1c91ba7b2141d1512709abac328ec1f2d4ed35b65699764\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "880214df48b6440dbe404c5d83936319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='downloading', max=724601837.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-09-08 21:22:14,526 - INFO - allennlp.models.archival - loading archive file https://s3-us-west-2.amazonaws.com/allennlp/models/fine-grained-ner-model-elmo-2018.12.21.tar.gz from cache at /Users/dylan/.allennlp/cache/a13840d22e17d9a789d2d5e4ec9a760e1051bd6311ee726660cbecdcdb2906f4.a306d04cf71c2432c1c91ba7b2141d1512709abac328ec1f2d4ed35b65699764\n",
      "2021-09-08 21:22:14,538 - INFO - allennlp.models.archival - extracting archive file /Users/dylan/.allennlp/cache/a13840d22e17d9a789d2d5e4ec9a760e1051bd6311ee726660cbecdcdb2906f4.a306d04cf71c2432c1c91ba7b2141d1512709abac328ec1f2d4ed35b65699764 to temp dir /var/folders/yf/tq71g5610qqdspnn_p_n4bc40000gn/T/tmpbo70ix_d\n",
      "2021-09-08 21:22:37,761 - INFO - allennlp.common.params - dataset_reader.type = ontonotes_ner\n",
      "2021-09-08 21:22:37,769 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /var/folders/yf/tq71g5610qqdspnn_p_n4bc40000gn/T/tmpbo70ix_d\n"
     ]
    },
    {
     "ename": "ConfigurationError",
     "evalue": "ontonotes_ner not in acceptable choices for dataset_reader.type: ['babi', 'conll2003', 'interleaving', 'multitask', 'multitask_shim', 'sequence_tagging', 'sharded', 'text_classification_json']. You should either use the --include-package flag to make sure the correct module is loaded, or use a fully qualified class name in your config file like {\"model\": \"my_module.models.MyModel\"} to have it imported automatically.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConfigurationError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b6ccd61d7836>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrump_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marticle_extraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrump\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPredictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://s3-us-west-2.amazonaws.com/allennlp/models/fine-grained-ner-model-elmo-2018.12.21.tar.gz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/allennlp/predictors/predictor.py\u001b[0m in \u001b[0;36mfrom_path\u001b[0;34m(cls, archive_path, predictor_name, cuda_device, dataset_reader_to_load, frozen, import_plugins, overrides, **kwargs)\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_plugins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         return Predictor.from_archive(\n\u001b[0;32m--> 366\u001b[0;31m             \u001b[0mload_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchive_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcuda_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m             \u001b[0mpredictor_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mdataset_reader_to_load\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_reader_to_load\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/allennlp/models/archival.py\u001b[0m in \u001b[0;36mload_archive\u001b[0;34m(archive_file, cuda_device, overrides, weights_file)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;31m# Instantiate model and dataset readers. Use a duplicate of the config, as it will get consumed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         dataset_reader, validation_dataset_reader = _load_dataset_readers(\n\u001b[0m\u001b[1;32m    233\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/allennlp/models/archival.py\u001b[0m in \u001b[0;36m_load_dataset_readers\u001b[0;34m(config, serialization_dir)\u001b[0m\n\u001b[1;32m    266\u001b[0m     )\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m     dataset_reader = DatasetReader.from_params(\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0mdataset_reader_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserialization_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/allennlp/common/from_params.py\u001b[0m in \u001b[0;36mfrom_params\u001b[0;34m(cls, params, constructor_to_call, constructor_to_inspect, **extras)\u001b[0m\n\u001b[1;32m    631\u001b[0m             \u001b[0mas_registrable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mType\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mRegistrable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mdefault_to_first_choice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_registrable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_implementation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             choice = params.pop_choice(\n\u001b[0m\u001b[1;32m    634\u001b[0m                 \u001b[0;34m\"type\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m                 \u001b[0mchoices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_registrable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/allennlp/common/params.py\u001b[0m in \u001b[0;36mpop_choice\u001b[0;34m(self, key, choices, default_to_first_choice, allow_class_names)\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0;34m\"\"\"{\"model\": \"my_module.models.MyModel\"} to have it imported automatically.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             )\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConfigurationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConfigurationError\u001b[0m: ontonotes_ner not in acceptable choices for dataset_reader.type: ['babi', 'conll2003', 'interleaving', 'multitask', 'multitask_shim', 'sequence_tagging', 'sharded', 'text_classification_json']. You should either use the --include-package flag to make sure the correct module is loaded, or use a fully qualified class name in your config file like {\"model\": \"my_module.models.MyModel\"} to have it imported automatically."
     ]
    }
   ],
   "source": [
    "trump_text = article_extraction(trump)\n",
    "from allennlp.predictors import Predictor\n",
    "al = Predictor.from_path(\"https://s3-us-west-2.amazonaws.com/allennlp/models/fine-grained-ner-model-elmo-2018.12.21.tar.gz\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Test1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
