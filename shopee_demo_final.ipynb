{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jabezlee/opt/anaconda3/lib/python3.7/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jabezlee/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import jellyfish\n",
    "from fuzzywuzzy import fuzz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from newspaper import Article\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "import dateutil.parser as parser\n",
    "from geopy.geocoders import Nominatim\n",
    "import pycountry\n",
    "import time\n",
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pinyin\n",
    "import sys\n",
    "\n",
    "from geopy.exc import GeocoderServiceError\n",
    "\n",
    "# Sentiment Analysis Packages\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "nltk.download('stopwords')\n",
    "\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name to be screened must be in English\n",
    "# Alias names can only handle Chinese characters , else return None\n",
    "def preprocess_df_to_dict(df):\n",
    "    def get_year(date):\n",
    "        try:\n",
    "            parser_obj = parser.parse(str(date))\n",
    "            return parser_obj.year\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def get_month(date):\n",
    "        if len(str(date))>4:\n",
    "            try:\n",
    "                return parser.parse(str(date)).month\n",
    "            except:\n",
    "                return None\n",
    "        else:\n",
    "            return None\n",
    "            \n",
    "    def get_day(date):\n",
    "        if len(str(date))>4:\n",
    "            try:\n",
    "                return parser.parse(str(date)).day\n",
    "            except:\n",
    "                return None\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def isEnglish(s):\n",
    "        try:\n",
    "            s.encode(encoding='utf-8').decode('ascii')\n",
    "        except UnicodeDecodeError:\n",
    "            return False\n",
    "        else:\n",
    "            return True    \n",
    "    \n",
    "    df_dict_list = df.to_dict('records')\n",
    "    cleaned_dict_list = []\n",
    "    for record in df_dict_list:\n",
    "        \n",
    "        alias = record['Alias name']\n",
    "        if alias is not None:\n",
    "            alias_is_english = isEnglish(alias)\n",
    "            if alias_is_english is False:\n",
    "                try:\n",
    "                    alias = pinyin.get(alias, format='strip', delimiter=' ')\n",
    "                except:\n",
    "                    alias = None\n",
    "        current_record = {\n",
    "            'name': record['Name to be screened'],\n",
    "            'alias' : alias,\n",
    "            'year_of_birth': get_year(record['Date of birth']),\n",
    "            'month_of_birth': get_month(record['Date of birth']),\n",
    "            'day_of_birth': get_day(record['Date of birth']),\n",
    "            'gender': record['Gender'],\n",
    "            'nationality': record['Nationality'],\n",
    "            ### delete these later on, for testing only###\n",
    "            'type_of_error': record['Type of variation (if any)'],\n",
    "            'actual_name': record['Actual name'],\n",
    "        }\n",
    "        cleaned_dict_list.append(current_record)\n",
    "    return cleaned_dict_list\n",
    "\n",
    "def ER_name_matching(name1, name2):\n",
    "    def split_name_list(name):\n",
    "        name = name.lower()\n",
    "        output = name.split(\" \")\n",
    "        return output\n",
    "\n",
    "    def preprocess_name(names_dict, word):\n",
    "        for key, value in names_dict.items():\n",
    "            if word in value:\n",
    "                return key\n",
    "        else:\n",
    "            return word\n",
    "\n",
    "    def stitch_name(list1):\n",
    "        output = ''\n",
    "        for x in range(len(list1)):\n",
    "            if x==0:\n",
    "                output += list1[x]\n",
    "            else:\n",
    "                output += ' ' + list1[x]\n",
    "        return output\n",
    "\n",
    "    def phonetic_comparison(list1, list2):\n",
    "        meta_list1 = []\n",
    "        meta_list2 = []\n",
    "        nysiis_list1 = []\n",
    "        nysiis_list2 = []\n",
    "        for name_1 in list1:\n",
    "            meta_list1.append(jellyfish.metaphone(name_1))\n",
    "            nysiis_list1.append(jellyfish.nysiis(name_1))\n",
    "        for name_2 in list2:\n",
    "            meta_list2.append(jellyfish.metaphone(name_2))\n",
    "            nysiis_list2.append(jellyfish.nysiis(name_2))\n",
    "        if (set(meta_list1) == set(meta_list2)) or (set(nysiis_list1) == set(nysiis_list2)):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def excel_to_dict(excel_file):\n",
    "        excel_df = pd.read_excel(excel_file)\n",
    "        excel_df.value.apply(str)\n",
    "        before_transformation = dict(zip(excel_df.key, excel_df.value))\n",
    "        dictionary = {key: [val for val in value.split(',')] for key, value in before_transformation.items()}\n",
    "        return dictionary\n",
    "            \n",
    "    names_dict = excel_to_dict('names_dict.xlsx') \n",
    "    \n",
    "    # START #\n",
    "    ### Change this if needed ###\n",
    "    threshold = 89\n",
    "    #############################\n",
    "    \n",
    "    split_list_1 = split_name_list(name1)\n",
    "    split_list_2 = split_name_list(name2) \n",
    " \n",
    "    \n",
    "    for i in range(len(split_list_1)):\n",
    "        split_list_1[i] = preprocess_name(names_dict, split_list_1[i])        \n",
    "    for i in range(len(split_list_2)):\n",
    "        split_list_2[i] = preprocess_name(names_dict, split_list_2[i])\n",
    "    \n",
    "    stitched_name1 = stitch_name(split_list_1)\n",
    "    stitched_name2 = stitch_name(split_list_2)\n",
    "    \n",
    "    # 1st layer of testing: Token Sort Ratio with threshold\n",
    "    score1 = fuzz.token_sort_ratio(stitched_name1, stitched_name2)\n",
    "    if score1 >= threshold:\n",
    "        # score_list.append(score1)\n",
    "        return score1\n",
    "        # do something\n",
    "# 4) 2nd layer of testing - Metaphone and NYSIIS phonetic encoding - DONE\n",
    "    else: \n",
    "        matched_phonetic = phonetic_comparison(split_list_1, split_list_2)\n",
    "        if matched_phonetic:\n",
    "            return threshold # assumption that phonetic match will give threshold score\n",
    "        else: \n",
    "            return None\n",
    "    \n",
    "    try:\n",
    "        return score1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# hlpr func: get country by cities, states name\n",
    "def get_country(gpe):\n",
    "    geolocator = Nominatim(user_agent = \"geoapiExercises\")\n",
    "    location = geolocator.geocode(gpe)\n",
    "    if location:\n",
    "        loc_lst = location.address.split(',')\n",
    "        return loc_lst[-1]\n",
    "    return None\n",
    "\n",
    "# hlpr func: return a list of countries names\n",
    "def countries():\n",
    "    return list(map(lambda x: x.name, list(pycountry.countries)))\n",
    "\n",
    "# hlpr func: return True if name countains country name\n",
    "def contain_country(word, ctry_lst):\n",
    "    for ctry in ctry_lst:\n",
    "        if ctry.lower() in word.lower():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# hlpr func: extract entities with tag 'GPE', 'ORG', 'NORP'\n",
    "def search_target_ent(tags):\n",
    "    country_lst = countries()\n",
    "    tag_lst = []\n",
    "    for i in range(len(tags)):\n",
    "        if tags[i][1] == 'GPE' or tags[i][1] == 'ORG' or tags[i][1] == 'NORP':\n",
    "            if contain_country(tags[i][0], country_lst):\n",
    "                tag_lst.append(tags[i])\n",
    "    return tag_lst\n",
    "\n",
    "# hlpr func: return the odd of the person's nationality in the article is nat\n",
    "def calc_odd_nationality(nat,lst):\n",
    "    try:\n",
    "        result = []\n",
    "        for tag in lst:\n",
    "            if tag[0] is not None and nat is not None:\n",
    "                if nat.lower() in tag[0].lower():\n",
    "                    result.append(tag)\n",
    "                    continue\n",
    "            try:\n",
    "                if tag[1] == 'GPE' and (get_country(tag[0]) is not None and nat is not None):\n",
    "                    if get_country(tag[0]).lower() == nat.lower():\n",
    "                        result.append(tag)\n",
    "            except GeocoderServiceError as e:\n",
    "                pass\n",
    "        prob = 1 if ((len(lst) - len(result)) == 0 and len(result) > 0) else (len(result) / (len(lst) - len(result)))\n",
    "        prob = 1 if prob > 1 else prob\n",
    "        return prob\n",
    "    except TypeError as e:\n",
    "        pass\n",
    "\n",
    "# hlpr func: return True if name fuzzy matching score > 80\n",
    "def is_target(name, article_name):\n",
    "    return fuzz.partial_ratio(name, article_name) > 80\n",
    "\n",
    "# the main function for nationality matching\n",
    "# return odd if target tags found else return 0\n",
    "def nationality_matching(tags, nationality, person):\n",
    "    \n",
    "    if nationality is None:\n",
    "        return None\n",
    "    \n",
    "    result = []\n",
    "    try:\n",
    "        for i in range(len(tags)):\n",
    "            #if second item is a name\n",
    "            if tags[i][1] == 'PERSON':\n",
    "                \n",
    "                # check if is target\n",
    "                if is_target(person, tags[i][0]):\n",
    "                    search = search_target_ent(tags)\n",
    "                \n",
    "                    if len(search) != 0:\n",
    "                        return calc_odd_nationality(nationality, search)\n",
    "        return 0\n",
    "    except IndexError as e:\n",
    "        pass\n",
    "\n",
    "# hlpr func: parse text to tags\n",
    "def parse(text):\n",
    "        #try:     \n",
    "        doc = nlp(text)\n",
    "        tags = [[X.text, X.label_] for X in doc.ents]\n",
    "        labels = [x.label_ for x in doc.ents]\n",
    "        items = [x.text for x in doc.ents]\n",
    "\n",
    "        return tags\n",
    "\n",
    "# hlpr func: return True if token is a name and subject\n",
    "def is_name_subj(token):\n",
    "    return (token.dep_ =='nsubj' or token.dep_ == 'nsubjpass')  and token.pos_ == 'PROPN'\n",
    "\n",
    "def is_part_of_name(token):\n",
    "    return (token.dep_ =='nsubj' or token.dep_ =='compound' or token.dep_ == 'nsubjpass') \\\n",
    "        and token.pos_ == 'PROPN'\n",
    "\n",
    "# hlpr func: return True if the token is a determiner: his, her, hers\n",
    "def is_det(token):\n",
    "    return token.pos_ == 'DET' and (token.dep_ == 'poss' or token.dep_ == 'attr')\n",
    "\n",
    "# hlpr func: return True if the token is a pronoun: he, she, herself, himself\n",
    "def is_pron(token):\n",
    "    return token.pos_ == 'PRON' and \\\n",
    "        (token.dep_ == 'nsubj' or token.dep_ == 'nsubjpass' or token.dep_ == 'pobj' or token.dep_ == 'dobj')\n",
    "\n",
    "# hlpr func: return True if the gender noun is referring to target person\n",
    "def refer_target(gender, noun, name, text):\n",
    "    m = ['man', 'boy', 'guy']\n",
    "    f = ['woman', 'lady', 'girl']\n",
    "    \n",
    "    if is_target(name, text):\n",
    "        return (gender == 'male' and noun in m) or (gender == 'female' and noun in f)\n",
    "    return 0\n",
    "\n",
    "# hlpr func: return True if gender noun is follwed by 'is, was, as or comma'\n",
    "def gender_noun(t1, t2):\n",
    "    gender_nouns = ['man', 'boy', 'guy', 'woman', 'lady', 'girl']\n",
    "    verbs = ['was', 'is', 'as', ',']\n",
    "    return (t1 in gender_nouns) and (t2 in verbs)\n",
    "\n",
    "# hlpr func: return the probability of the gender in article to the true gender\n",
    "def calc_prob_gender(pron_lst, gender):\n",
    "    male_pron = ['he', 'his', 'himself', 'him']\n",
    "    female_pron = ['she', 'her', 'herself', 'hers']\n",
    "    n_target = 0\n",
    "    gdr_pron = []\n",
    "    \n",
    "    if gender.lower() == 'male':\n",
    "        gdr_pron = male_pron\n",
    "    else:\n",
    "        gdr_pron = female_pron\n",
    "        \n",
    "    for pron in pron_lst:\n",
    "        if pron in gdr_pron:\n",
    "            n_target += 1\n",
    "    return n_target / len(pron_lst) if len(pron_lst) else 0\n",
    "\n",
    "# the main function in gender matching\n",
    "def gender_matching(text, gender, name):\n",
    "    \n",
    "    if gender is None:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        pron_lst = ['he', 'his', 'himself', 'him', 'she', 'her', 'herself', 'hers']\n",
    "        name_str = ''\n",
    "        target_name = name.replace(\" \", \"\")\n",
    "        target_found = False\n",
    "        res_lst = []\n",
    "        \n",
    "        # text tagging\n",
    "        doc = nlp(text)\n",
    "        \n",
    "        i = 0\n",
    "        while i < len(doc):\n",
    "\n",
    "            # catch text like '...woman is/was/as/, xxx...'\n",
    "            if gender_noun(doc[i].text, doc[i + 1].text):\n",
    "                if refer_target(gender.lower(), doc[i].text, name, doc[i + 2].text):\n",
    "                    return (1)\n",
    "\n",
    "            # search for target name of subject form\n",
    "            if is_name_subj(doc[i]):\n",
    "                end_name = i\n",
    "                start_name = i\n",
    "                while is_part_of_name(doc[start_name]):\n",
    "                    start_name -= 1\n",
    "                start_name += 1\n",
    "                while start_name <= end_name:\n",
    "                    name_str += doc[start_name].text\n",
    "                    start_name += 1\n",
    "\n",
    "            if is_target(name_str, target_name):\n",
    "                target_found = True\n",
    "            else:\n",
    "                name_str = ''\n",
    "                target_found = False\n",
    "          \n",
    "            # if target name is found, search for pronouns, break if another name is found\n",
    "            while target_found:\n",
    "                i+=1\n",
    "                if gender_noun(doc[i].text, doc[i + 1].text):\n",
    "                    if refer_target(gender.lower(), doc[i].text, name, doc[i + 2].text):\n",
    "                        return (1)\n",
    "                if is_name_subj(doc[i]):\n",
    "                    target_found = False\n",
    "                    name_str = ''\n",
    "                    break\n",
    "                if is_det(doc[i]) or is_pron(doc[i]):\n",
    "                    if (doc[i].text).lower() in pron_lst:\n",
    "                        res_lst.append((doc[i].text).lower())\n",
    "                        break\n",
    "\n",
    "            i += 1\n",
    "    except IndexError as e:\n",
    "        pass\n",
    "    return calc_prob_gender(res_lst, gender)\n",
    "\n",
    "useless_dates = ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday','yesterday','today']\n",
    "\n",
    "#index is index of person\n",
    "def forward_searcher(index,tags):\n",
    "    for i in range(index,len(tags)):\n",
    "        if tags[i][1] == 'DATE' and tags[i][0] not in useless_dates:\n",
    "            return tags[i]\n",
    "    return [None,None]\n",
    "\n",
    "def backward_searcher(index,tags):\n",
    "    i = index\n",
    "    while i >= 0:\n",
    "        if tags[i][1] == 'DATE' and tags[i][0] not in useless_dates:\n",
    "            return tags[i]\n",
    "        else:\n",
    "            i -=1\n",
    "\n",
    "def detect_age(age,lst):\n",
    "    try:\n",
    "        if lst[1] is not None and lst[2] is not None:\n",
    "            date1 = lst[1][0]\n",
    "            date2 = lst[2][0]\n",
    "            if (str(age) in date1) or (str(age) in date2):\n",
    "                return True\n",
    "        else:\n",
    "\n",
    "            if lst[1] == None:\n",
    "                if str(age) in lst[2][0]:\n",
    "                    return True\n",
    "\n",
    "            if lst[2] == None:\n",
    "                if str(age) in lst[1][0]:\n",
    "                    return True\n",
    "    except TypeError as e:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "def confirm_age(lst,age,threshold):\n",
    "    iterating_lst = []\n",
    "    plus = 1\n",
    "    minus = -1\n",
    "    for i in range(threshold):\n",
    "        iterating_lst.append(age+plus)\n",
    "        plus += 1\n",
    "    for i in range(threshold):\n",
    "        iterating_lst.append(age+minus)\n",
    "        minus -=1 \n",
    "    iterating_lst.append(age)\n",
    "    \n",
    "    for j in iterating_lst:\n",
    "        if str(j) in lst[1][0]:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def age_matching(name_dict,tags,age):\n",
    "    '''\n",
    "    tags: parse(text)\n",
    "    age: desired age to check\n",
    "    '''\n",
    "    if age is None:\n",
    "        return None\n",
    "    \n",
    "    for tag in tags:\n",
    "        #if tag[1] == 'DATE':\n",
    "            #print(tag)\n",
    "        if str(age) in tag[0] or str(age+1) in tag[0] or str(age-1) in tag[0]:\n",
    "            return 1\n",
    "    result = []\n",
    "    try:\n",
    "        for i in range(len(tags)):\n",
    "            #if second item is a name\n",
    "\n",
    "            \n",
    "            if tags[i][1] == 'PERSON':\n",
    "                if tags[i][0] in name_dict:\n",
    "\n",
    "                    forward_age = forward_searcher(i,tags)\n",
    "                    backwards_age = backward_searcher(i,tags)\n",
    "                    new_list = [tags[i],forward_age,backwards_age]\n",
    "                    #new_list = [tags[i-1],tags[i],tags[i+1]]\n",
    "                    #print(new_list)\n",
    "\n",
    "                    if detect_age(age,new_list) and tags[i][0] in name_list:\n",
    "\n",
    "                        #print(new_list)\n",
    "                        #result += new_list\n",
    "\n",
    "                        if str(age) in new_list[1][0]:\n",
    "                            #print('****************')\n",
    "                            #print([tags[i], new_list[1]])\n",
    "                            return(confirm_age([tags[i],new_list[1]],age,3))\n",
    "\n",
    "\n",
    "                        elif str(age) in new_list[2][0]:\n",
    "                            #print('****************')\n",
    "                            #print([tags[i],new_list[2]])\n",
    "                            return(confirm_age([tags[i],new_list[2]],age,3))\n",
    "                        \n",
    "        return 0\n",
    "    except IndexError as e:\n",
    "        pass\n",
    "    \n",
    "def entity_recognition_scoring_each_article(input_info, text, names_list):\n",
    "    output = []\n",
    "    input_name = input_info['name']\n",
    "\n",
    "\n",
    "    article_names_list = names_list.most_common() \n",
    "    matched = False\n",
    "\n",
    "    for each_name, each_count in article_names_list: ## as of now checking all names within the article, should we limit to e.g. top 3/5?\n",
    "        if len(each_name.split()) == 1 and each_name in input_name:\n",
    "            score = 100 ## if surname matches, default match score 100 \n",
    "        else: \n",
    "            try: \n",
    "                score = ER_name_matching(input_name, each_name)\n",
    "            except ValueError as e:\n",
    "                pass\n",
    "        if score is not None:\n",
    "            matched = True\n",
    "        if matched:\n",
    "            break\n",
    "    conf_score = 0\n",
    "    if matched:\n",
    "        name_score = score\n",
    "        nationality_score = nationality_matching(parse(text), input_info['nationality'], input_info['name'])\n",
    "        gender_score = gender_matching(text, input_info['gender'], input_info['name'])\n",
    "        age_score = age_matching(names_list,parse(text),input_info['year_of_birth'])\n",
    "        \n",
    "        denom = 0.9071\n",
    "        if nationality_score is not None:\n",
    "            denom += 0.049973\n",
    "        if gender_score is not None:\n",
    "            denom += 0.030293\n",
    "        if age_score is not None:\n",
    "            denom += 0.012634\n",
    "\n",
    "        conf_score = ((0.9071 / denom) * (name_score/100))\n",
    "\n",
    "        if nationality_score is not None:\n",
    "            conf_score += ((0.049973 / denom) * nationality_score)\n",
    "        if gender_score is not None:\n",
    "            conf_score += ((0.030293 / denom) * gender_score)\n",
    "        if age_score is not None:\n",
    "            conf_score += ((0.012634 / denom) * age_score)\n",
    "                           \n",
    "    return conf_score\n",
    "    \n",
    "# Main Function\n",
    "def search_articles_on_individual(individual_dict, no_of_articles=30):\n",
    "    def generate_link(person_dict, attributes_used = ['name'], keywords=['crimes', 'sentenced']):\n",
    "        link_start = \"https://www.google.com/search?q=\"\n",
    "        link_end = \"&sxsrf=ALeKk01K1bOuJFHjy4HBARo1cRpUYakYPg:1629640327633&source=lnms&tbm=nws&sa=X&sqi=2&ved=2ahUKEwiu29um48TyAhWGqpUCHYuoAlcQ_AUoAnoECAEQBA&biw=1441&bih=718&dpr=2\" \n",
    "        link_query = \"\"\n",
    "\n",
    "        for attributes in attributes_used:\n",
    "            temp_attr = person_dict[attributes]\n",
    "            if temp_attr is not None:\n",
    "                temp_attr = str(temp_attr)\n",
    "                link_query += temp_attr.replace(' ', '+') + '+'       \n",
    "                \n",
    "        links = []\n",
    "        for keyword in keywords:\n",
    "            temp_search_link = link_start + link_query + keyword + link_end + \"&num=\" + str(no_of_articles)\n",
    "            links.append(temp_search_link)\n",
    "        return links\n",
    "    \n",
    "    def article_extraction(link):\n",
    "        article = Article(link)\n",
    "        article.download()\n",
    "        try:\n",
    "            article.parse()\n",
    "        except:\n",
    "            pass\n",
    "        return article.text\n",
    "\n",
    "    def parse(text):\n",
    "        #try:     \n",
    "        doc = nlp(text)\n",
    "        tags = [[X.text, X.label_] for X in doc.ents]\n",
    "        labels = [x.label_ for x in doc.ents]\n",
    "        items = [x.text for x in doc.ents]\n",
    "\n",
    "        return tags\n",
    "\n",
    "    def find_names(tags):\n",
    "        names = []\n",
    "        for tag in tags:\n",
    "            if tag[1] == 'PERSON':\n",
    "                names.append(tag[0])\n",
    "        return names\n",
    "    \n",
    "    def time_to_months(time):\n",
    "        if 'weeks' in time:\n",
    "            return 0\n",
    "        else:\n",
    "            return int(time.split(' month')[0])\n",
    "\n",
    "    search_links = generate_link(individual_dict)\n",
    "    \n",
    "    unique_links_checker = []\n",
    "    \n",
    "    output = []\n",
    "    for x in search_links:\n",
    "        req = Request(x, headers = {'User-Agent': 'Mozilla/5.0'})\n",
    "\n",
    "        webpage = urlopen(req).read()\n",
    "\n",
    "        with requests.Session() as c:\n",
    "            soup = BeautifulSoup(webpage, 'html5lib')\n",
    "            #print(soup)\n",
    "            for item in soup.find_all('div', attrs = {'class': \"ZINbbc xpd O9g5cc uUPGi\"}):\n",
    "                current_dict = {}\n",
    "                raw_link = (item.find('a', href = True)['href'])\n",
    "                try:\n",
    "                    link = (raw_link.split(\"/url?q=\")[1]).split('&sa=U&')[0]\n",
    "                except IndexError as e1:\n",
    "                    continue\n",
    "                if link not in unique_links_checker and item:\n",
    "                    unique_links_checker.append(link)\n",
    "                    title = item.find('div',attrs = {'class': 'BNeawe vvjwJb AP7Wnd'})\n",
    "                    if title == None:\n",
    "                        continue\n",
    "                    title = title.get_text()\n",
    "                    description  = (item.find('div',attrs = {'class': 'BNeawe s3v9rd AP7Wnd'}).get_text())\n",
    "                    time = description.split(\" · \")[0]\n",
    "                    #print(description)\n",
    "                    descript = description.split(\" · \")[1]\n",
    "                    \n",
    "                    # create names_list\n",
    "                    parsed_description = parse(description)\n",
    "                    names_in_description = find_names(parsed_description) \n",
    "                    parsed_text = parse(article_extraction(link))\n",
    "                    names_in_text = find_names(parsed_text)\n",
    "                    names_list = Counter(names_in_description + names_in_text)\n",
    "                    \n",
    "                    # extract text\n",
    "                    text = article_extraction(link)\n",
    "\n",
    "                    # compute confidence score before accepting the article\n",
    "                    conf_score = entity_recognition_scoring_each_article(individual_dict, text, names_list)\n",
    "                    \n",
    "                    # this is the new part 0.9071\n",
    "                    overall_threshold = 0.8\n",
    "                    \n",
    "                    nationality = individual_dict['nationality']\n",
    "                    gender = individual_dict['gender']\n",
    "                    year_of_birth = individual_dict['year_of_birth']\n",
    "                    \n",
    "                    if nationality is not None:\n",
    "                        overall_threshold += 0.049973\n",
    "                    if gender is not None:\n",
    "                        overall_threshold += 0.030293\n",
    "                    if year_of_birth is not None:\n",
    "                        overall_threshold += 0.012634\n",
    "                  \n",
    "\n",
    "                    if conf_score < overall_threshold:\n",
    "                        continue\n",
    "            \n",
    "                    current_dict['title'] = title\n",
    "                    current_dict['time'] = time\n",
    "                    try:\n",
    "                        current_dict['year_of_birth'] = (date.today() - relativedelta(months = time_to_months(time))).year - individual_dict['year_of_birth']\n",
    "                    except TypeError as e1:\n",
    "                        current_dict['year_of_birth'] = 0\n",
    "                    except ValueError as e2:\n",
    "                        current_dict['year_of_birth'] = 0\n",
    "                    current_dict['description'] = descript\n",
    "                    current_dict['link'] = link\n",
    "                    current_dict['text'] = text\n",
    "                    current_dict['names_list'] = names_list\n",
    "                    current_dict['confidence_score'] = conf_score\n",
    "                    \n",
    "                    output.append(current_dict)\n",
    "                else:\n",
    "                    pass\n",
    "    return output\n",
    "\n",
    "# Sentiment Analysis\n",
    "def sentiment_model(name_matched):\n",
    "    \n",
    "    if len(name_matched) == 0:\n",
    "        sys.exit(\"No Articles found.\")\n",
    "        \n",
    "    else:\n",
    "    \n",
    "        # Loading Model\n",
    "        reconstructed_model = keras.models.load_model(\"LSTM_GLOVE\")\n",
    "\n",
    "        url = r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)\n",
    "        (?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([\n",
    "          ^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))'''\n",
    "\n",
    "        tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "        def clean_data(temp):\n",
    "            temp = temp.map(lambda x:str(x).lower()) \n",
    "            # removing emails\n",
    "            temp = temp.map(lambda x:re.sub(r\"\\b[^\\s]+@[^\\s]+[.][^\\s]+\\b\", \"\", x)) \n",
    "            # removing url\n",
    "            temp = temp.map(lambda x:re.sub(url, \"\", x)) \n",
    "            # removing numbers\n",
    "            temp = temp.map(lambda x:re.sub(r'[^a-zA-z.,!?/:;\\\"\\'\\s]', \"\", x)) \n",
    "            # removing white space\n",
    "            temp = temp.map(lambda x:re.sub(r'^\\s*|\\s\\s*', ' ', x).strip()) \n",
    "            # removing punctuations\n",
    "            temp = temp.map(lambda x:''.join([c for c in x if c not in string.punctuation])) \n",
    "            # removing special characters\n",
    "            temp = temp.map(lambda x:re.sub(r'[^a-zA-z0-9.,!?/:;\\\"\\'\\s]', '', x)) \n",
    "            # unicode\n",
    "            temp = temp.map(lambda x:unicodedata.normalize('NFKD', x).encode('ascii', 'ignore').decode('utf-8', 'ignore')) \n",
    "            # tokenising text for cleaning\n",
    "            temp = temp.map(lambda x:tokenizer.tokenize(x)) \n",
    "            # removing stop words\n",
    "            temp = temp.map(lambda x:[i for i in x if i not in stopwords.words('english')]) \n",
    "            temp = temp.map(lambda x:' '.join(x))\n",
    "            return temp\n",
    "\n",
    "        name_matched['body'] = name_matched['text']\n",
    "        name_matched.text = clean_data(name_matched.text)\n",
    "\n",
    "        # Data Preprocessing for model ingestion\n",
    "        maxlen = 50\n",
    "        embedding_dim = 100\n",
    "\n",
    "        X = name_matched.text.values\n",
    "        tokenizer = Tokenizer(num_words=5000)\n",
    "        tokenizer.fit_on_texts(name_matched.text.values)\n",
    "        X = tokenizer.texts_to_sequences(X)\n",
    "        vocab_size = len(tokenizer.word_index) + 1\n",
    "        test_input = pad_sequences(X, padding='pre', maxlen=maxlen)\n",
    "\n",
    "        # Predicting output\n",
    "        test = reconstructed_model.predict(test_input)\n",
    "        test_classes = np.argmax(test,axis=1)\n",
    "        name_matched['prediction'] = test_classes\n",
    "        \n",
    "        def predicted_classes(df):\n",
    "            val = ''  \n",
    "            if df['prediction'] == 2:\n",
    "                val = 'negative'\n",
    "            elif df['prediction'] == 0:\n",
    "                val = 'neutral'\n",
    "            else:\n",
    "                val = 'positive'\n",
    "\n",
    "            return val\n",
    "\n",
    "        name_matched['sentiment'] = name_matched.apply(predicted_classes,axis=1)\n",
    "        name_matched = name_matched[['title', 'time', 'year_of_birth', 'description', 'link', 'body',\n",
    "                                       'names_list', 'confidence_score', 'sentiment']]\n",
    "    \n",
    "        return name_matched\n",
    "\n",
    "def demo(input):\n",
    "    # Web Scraping\n",
    "    df = pd.read_excel(\"Shopee Test.xlsx\", engine=\"openpyxl\")\n",
    "    df = df.where(pd.notnull(df), None)\n",
    "    df_dict = preprocess_df_to_dict(df)\n",
    "    test_record_1 = df_dict[input]\n",
    "    \n",
    "    print('Test input: \\n')\n",
    "    print('Name: ' + str(test_record_1['actual_name']))\n",
    "    print('Alias: ' + str(test_record_1['alias']))\n",
    "    print('Year of Birth: ' + str(test_record_1['year_of_birth']))\n",
    "    print('Month of Birth: ' + str(test_record_1['month_of_birth']))\n",
    "    print('Day of Birth: ' + str(test_record_1['day_of_birth']))\n",
    "    print('Gender: ' + str(test_record_1['gender']))\n",
    "    print('Nationality: ' + str(test_record_1['nationality']))\n",
    "\n",
    "    print('\\n')\n",
    "\n",
    "    test_query = search_articles_on_individual(test_record_1, 10)\n",
    "    test_query = pd.DataFrame(test_query)\n",
    "\n",
    "    # Sentiment Analysis\n",
    "    output = sentiment_model(test_query)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individuals associated with Financial Crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test input: \n",
      "\n",
      "Name: Tan Wee Beng\n",
      "Alias: None\n",
      "Year of Birth: 1977\n",
      "Month of Birth: None\n",
      "Day of Birth: None\n",
      "Gender: Male\n",
      "Nationality: Singapore\n",
      "\n",
      "\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8784ef4200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "CPU times: user 11.3 s, sys: 444 ms, total: 11.8 s\n",
      "Wall time: 39.9 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>time</th>\n",
       "      <th>year_of_birth</th>\n",
       "      <th>description</th>\n",
       "      <th>link</th>\n",
       "      <th>body</th>\n",
       "      <th>names_list</th>\n",
       "      <th>confidence_score</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S'pore businessman wanted by FBI pleads guilty...</td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>0</td>\n",
       "      <td>Tan Wee Beng is on the FBI's most wanted list ...</td>\n",
       "      <td>https://www.straitstimes.com/singapore/courts-...</td>\n",
       "      <td>SINGAPORE - A Singaporean businessman, on the ...</td>\n",
       "      <td>{'Tan Wee Beng': 2, 'Tan': 12, 'Wee Tiong': 4,...</td>\n",
       "      <td>0.987366</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Singaporean on FBI's most wanted list charged ...</td>\n",
       "      <td>15 months ago</td>\n",
       "      <td>43</td>\n",
       "      <td>Tan Wee Beng is the managing director of Wee T...</td>\n",
       "      <td>https://www.channelnewsasia.com/singapore/sing...</td>\n",
       "      <td>SINGAPORE: A 43-year-old Singaporean managing ...</td>\n",
       "      <td>{'Tan Wee Beng': 2, 'Wee Tiong': 3, 'Tan': 5, ...</td>\n",
       "      <td>0.957073</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Singapore trader denies laundering millions fo...</td>\n",
       "      <td>35 months ago</td>\n",
       "      <td>41</td>\n",
       "      <td>Tan Wee Beng told the BBC that he had only lea...</td>\n",
       "      <td>https://www.bbc.co.uk/news/world-asia-45987533</td>\n",
       "      <td>The US Treasury has now placed sanctions on Mr...</td>\n",
       "      <td>{'Tan Wee Beng': 1, 'Mr Tan': 1, 'Wee Tiong': 1}</td>\n",
       "      <td>0.907100</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Singaporean MD on FBI most wanted list charged...</td>\n",
       "      <td>15 months ago</td>\n",
       "      <td>43</td>\n",
       "      <td>Tan Wee Beng, a 43-year old Singaporean managi...</td>\n",
       "      <td>https://www.manifoldtimes.com/news/singaporean...</td>\n",
       "      <td>Tan Wee Beng, a 43-year old Singaporean managi...</td>\n",
       "      <td>{'Tan Wee Beng': 4, 'Wee Tiong': 3, 'Tan': 4, ...</td>\n",
       "      <td>0.987366</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Singaporean accused of N. Korea dealings to ta...</td>\n",
       "      <td>35 months ago</td>\n",
       "      <td>41</td>\n",
       "      <td>SINGAPORE (AP) -- A Singaporean businessman fa...</td>\n",
       "      <td>https://mainichi.jp/english/articles/20181031/...</td>\n",
       "      <td>This wanted poster released by FBI shows Singa...</td>\n",
       "      <td>{'Wee Tiong': 6, 'Tan Wee Beng': 2, 'Singapore...</td>\n",
       "      <td>0.987366</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FBI Seeks Trader Accused of Violating North Ko...</td>\n",
       "      <td>35 months ago</td>\n",
       "      <td>41</td>\n",
       "      <td>Beng (aliases \"WB\", Wee Beng Tan, Marcus Tan, ...</td>\n",
       "      <td>https://www.maritime-executive.com/article/fbi...</td>\n",
       "      <td>FBI Seeks Trader Accused of Violating North Ko...</td>\n",
       "      <td>{'Beng': 6, 'Wee Beng Tan': 2, 'Marcus Tan': 2...</td>\n",
       "      <td>0.974873</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Top stories from The Straits Times on Friday, ...</td>\n",
       "      <td>35 months ago</td>\n",
       "      <td>41</td>\n",
       "      <td>US imposes North Korea-related sanctions on Si...</td>\n",
       "      <td>https://www.straitstimes.com/singapore/top-sto...</td>\n",
       "      <td>US imposes North Korea-related sanctions on Si...</td>\n",
       "      <td>{'Tan Wee Beng': 2, 'Steven Chong': 2, 'Davind...</td>\n",
       "      <td>0.957073</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Singapore commodity broker wanted by FBI charg...</td>\n",
       "      <td>15 months ago</td>\n",
       "      <td>43</td>\n",
       "      <td>Tan Wee Beng, managing director of trading com...</td>\n",
       "      <td>https://www.malaymail.com/news/singapore/2020/...</td>\n",
       "      <td>The North Korea flag flutters next to concerti...</td>\n",
       "      <td>{'Tan Wee Beng': 2, 'Wee Tiong': 3, 'Tan': 3}</td>\n",
       "      <td>0.957073</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4 scooter riders jailed for assaulting Argenti...</td>\n",
       "      <td>41 months ago</td>\n",
       "      <td>41</td>\n",
       "      <td>The four — Thomas Leong Sin Kwang, 37, Tay Woe...</td>\n",
       "      <td>https://stomp.straitstimes.com/singapore-seen/...</td>\n",
       "      <td>Four motor scooter riders were sentenced to ja...</td>\n",
       "      <td>{'Thomas Leong Sin Kwang': 2, 'Tay Woei Chain'...</td>\n",
       "      <td>0.930661</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Food stall attendant who stomped on man's face...</td>\n",
       "      <td>31 months ago</td>\n",
       "      <td>42</td>\n",
       "      <td>The older man was later taken to Tan Tock Seng...</td>\n",
       "      <td>https://stomp.straitstimes.com/singapore-seen/...</td>\n",
       "      <td>Shaffiq Alkhatib\\n\\nThe Straits Times\\n\\nFeb 1...</td>\n",
       "      <td>{'Wee': 7, 'Shaffiq Alkhatib': 1, 'Wee Boon': ...</td>\n",
       "      <td>0.987366</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Hotel executive pretended to be offended by co...</td>\n",
       "      <td>12 months ago</td>\n",
       "      <td>43</td>\n",
       "      <td>Mr Tan had tried to claim he was not friends w...</td>\n",
       "      <td>https://www.dailymail.co.uk/news/article-87482...</td>\n",
       "      <td>A high-flying hotel executive who described hi...</td>\n",
       "      <td>{'Mr Tan': 11, 'Catherine Wu': 3, 'Kwek Leng B...</td>\n",
       "      <td>0.907100</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title           time  \\\n",
       "0   S'pore businessman wanted by FBI pleads guilty...      1 day ago   \n",
       "1   Singaporean on FBI's most wanted list charged ...  15 months ago   \n",
       "2   Singapore trader denies laundering millions fo...  35 months ago   \n",
       "3   Singaporean MD on FBI most wanted list charged...  15 months ago   \n",
       "4   Singaporean accused of N. Korea dealings to ta...  35 months ago   \n",
       "5   FBI Seeks Trader Accused of Violating North Ko...  35 months ago   \n",
       "6   Top stories from The Straits Times on Friday, ...  35 months ago   \n",
       "7   Singapore commodity broker wanted by FBI charg...  15 months ago   \n",
       "8   4 scooter riders jailed for assaulting Argenti...  41 months ago   \n",
       "9   Food stall attendant who stomped on man's face...  31 months ago   \n",
       "10  Hotel executive pretended to be offended by co...  12 months ago   \n",
       "\n",
       "    year_of_birth                                        description  \\\n",
       "0               0  Tan Wee Beng is on the FBI's most wanted list ...   \n",
       "1              43  Tan Wee Beng is the managing director of Wee T...   \n",
       "2              41  Tan Wee Beng told the BBC that he had only lea...   \n",
       "3              43  Tan Wee Beng, a 43-year old Singaporean managi...   \n",
       "4              41  SINGAPORE (AP) -- A Singaporean businessman fa...   \n",
       "5              41  Beng (aliases \"WB\", Wee Beng Tan, Marcus Tan, ...   \n",
       "6              41  US imposes North Korea-related sanctions on Si...   \n",
       "7              43  Tan Wee Beng, managing director of trading com...   \n",
       "8              41  The four — Thomas Leong Sin Kwang, 37, Tay Woe...   \n",
       "9              42  The older man was later taken to Tan Tock Seng...   \n",
       "10             43  Mr Tan had tried to claim he was not friends w...   \n",
       "\n",
       "                                                 link  \\\n",
       "0   https://www.straitstimes.com/singapore/courts-...   \n",
       "1   https://www.channelnewsasia.com/singapore/sing...   \n",
       "2      https://www.bbc.co.uk/news/world-asia-45987533   \n",
       "3   https://www.manifoldtimes.com/news/singaporean...   \n",
       "4   https://mainichi.jp/english/articles/20181031/...   \n",
       "5   https://www.maritime-executive.com/article/fbi...   \n",
       "6   https://www.straitstimes.com/singapore/top-sto...   \n",
       "7   https://www.malaymail.com/news/singapore/2020/...   \n",
       "8   https://stomp.straitstimes.com/singapore-seen/...   \n",
       "9   https://stomp.straitstimes.com/singapore-seen/...   \n",
       "10  https://www.dailymail.co.uk/news/article-87482...   \n",
       "\n",
       "                                                 body  \\\n",
       "0   SINGAPORE - A Singaporean businessman, on the ...   \n",
       "1   SINGAPORE: A 43-year-old Singaporean managing ...   \n",
       "2   The US Treasury has now placed sanctions on Mr...   \n",
       "3   Tan Wee Beng, a 43-year old Singaporean managi...   \n",
       "4   This wanted poster released by FBI shows Singa...   \n",
       "5   FBI Seeks Trader Accused of Violating North Ko...   \n",
       "6   US imposes North Korea-related sanctions on Si...   \n",
       "7   The North Korea flag flutters next to concerti...   \n",
       "8   Four motor scooter riders were sentenced to ja...   \n",
       "9   Shaffiq Alkhatib\\n\\nThe Straits Times\\n\\nFeb 1...   \n",
       "10  A high-flying hotel executive who described hi...   \n",
       "\n",
       "                                           names_list  confidence_score  \\\n",
       "0   {'Tan Wee Beng': 2, 'Tan': 12, 'Wee Tiong': 4,...          0.987366   \n",
       "1   {'Tan Wee Beng': 2, 'Wee Tiong': 3, 'Tan': 5, ...          0.957073   \n",
       "2    {'Tan Wee Beng': 1, 'Mr Tan': 1, 'Wee Tiong': 1}          0.907100   \n",
       "3   {'Tan Wee Beng': 4, 'Wee Tiong': 3, 'Tan': 4, ...          0.987366   \n",
       "4   {'Wee Tiong': 6, 'Tan Wee Beng': 2, 'Singapore...          0.987366   \n",
       "5   {'Beng': 6, 'Wee Beng Tan': 2, 'Marcus Tan': 2...          0.974873   \n",
       "6   {'Tan Wee Beng': 2, 'Steven Chong': 2, 'Davind...          0.957073   \n",
       "7       {'Tan Wee Beng': 2, 'Wee Tiong': 3, 'Tan': 3}          0.957073   \n",
       "8   {'Thomas Leong Sin Kwang': 2, 'Tay Woei Chain'...          0.930661   \n",
       "9   {'Wee': 7, 'Shaffiq Alkhatib': 1, 'Wee Boon': ...          0.987366   \n",
       "10  {'Mr Tan': 11, 'Catherine Wu': 3, 'Kwek Leng B...          0.907100   \n",
       "\n",
       "   sentiment  \n",
       "0   negative  \n",
       "1   negative  \n",
       "2   negative  \n",
       "3   positive  \n",
       "4   negative  \n",
       "5   negative  \n",
       "6    neutral  \n",
       "7   positive  \n",
       "8   positive  \n",
       "9   negative  \n",
       "10  positive  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 4 Tay Sheng Yang: Singaporean involved fraudulent cashback schemes that cheated Spring Singapore and the WDA\n",
    "# 3 Ng Yu Zhi: The former director of Envy Global Trading - Charged with running the Singapore largest Ponzi scheme\n",
    "\n",
    "demo(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individuals associated with Non-Financial Crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test input: \n",
      "\n",
      "Name: Mas Selamat Kastari\n",
      "Alias: None\n",
      "Year of Birth: 1961\n",
      "Month of Birth: 1\n",
      "Day of Birth: 23\n",
      "Gender: Male\n",
      "Nationality: Singapore\n",
      "Actual Name: Mas Selamat Kastari\n",
      "\n",
      "\n",
      "CPU times: user 14.2 s, sys: 811 ms, total: 15 s\n",
      "Wall time: 3min 23s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>time</th>\n",
       "      <th>year_of_birth</th>\n",
       "      <th>description</th>\n",
       "      <th>link</th>\n",
       "      <th>body</th>\n",
       "      <th>names_list</th>\n",
       "      <th>confidence_score</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mas Selamat hid butter, used mineral water bot...</td>\n",
       "      <td>54 months ago</td>\n",
       "      <td>56</td>\n",
       "      <td>Mas Selamat Kastari (centre) leaving the Tanju...</td>\n",
       "      <td>https://www.straitstimes.com/asia/se-asia/mas-...</td>\n",
       "      <td>KUALA LUMPUR (THE STAR/ASIA NEWS NETWORK) - He...</td>\n",
       "      <td>{'Mas Selamat Kastari': 1, 'Stulang Laut': 1, ...</td>\n",
       "      <td>0.987366</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Former Supreme Court judge Goh Joon Seng dies,...</td>\n",
       "      <td>3 months ago</td>\n",
       "      <td>60</td>\n",
       "      <td>... set up to investigate the escape of Jemaah...</td>\n",
       "      <td>https://www.straitstimes.com/singapore/former-...</td>\n",
       "      <td>SINGAPORE - Former Supreme Court judge Goh Joo...</td>\n",
       "      <td>{'Mas Selamat Kastari': 2, 'Goh Joon Seng': 1,...</td>\n",
       "      <td>0.957073</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Son of Mas Selamat: 10 years studying, teachin...</td>\n",
       "      <td>95 months ago</td>\n",
       "      <td>52</td>\n",
       "      <td>Masyhadi's father, former Jemaah Islamiah lead...</td>\n",
       "      <td>https://www.straitstimes.com/singapore/son-of-...</td>\n",
       "      <td>The several hundred neighbours who attended th...</td>\n",
       "      <td>{'Mas Selamat Kastari': 2, 'Muhammad Hanif': 2...</td>\n",
       "      <td>0.983797</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ex-ISD chief: loyalty key lesson from Mas Sela...</td>\n",
       "      <td>92 months ago</td>\n",
       "      <td>53</td>\n",
       "      <td>The senior civil servant under whose watch Mas...</td>\n",
       "      <td>https://www.straitstimes.com/singapore/ex-isd-...</td>\n",
       "      <td>The senior civil servant under whose watch Mas...</td>\n",
       "      <td>{'Mas Selamat Kastari': 2, 'Pang Kin Keong': 1...</td>\n",
       "      <td>0.987366</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Singapore's most wanted man nabbed in Malaysia</td>\n",
       "      <td>149 months ago</td>\n",
       "      <td>48</td>\n",
       "      <td>Security experts said the capture of Mas Selam...</td>\n",
       "      <td>https://www.reuters.com/article/us-singapore-m...</td>\n",
       "      <td>SINGAPORE (Reuters) - The suspected leader of ...</td>\n",
       "      <td>{'Mas Selamat Kastari': 3, 'Bali': 2, 'Wong Ka...</td>\n",
       "      <td>0.987366</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>First Singaporean in an ISIS video: 3 question...</td>\n",
       "      <td>48 months ago</td>\n",
       "      <td>56</td>\n",
       "      <td>... and captured Jemaah Islamiah (JI) leader M...</td>\n",
       "      <td>https://www.straitstimes.com/singapore/first-s...</td>\n",
       "      <td>1. Why feature a Singaporean?\\n\\nAlthough ISIS...</td>\n",
       "      <td>{'Mas Selamat Kastari': 2, 'Megat Shahdan Abdu...</td>\n",
       "      <td>0.957073</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title            time  \\\n",
       "0  Mas Selamat hid butter, used mineral water bot...   54 months ago   \n",
       "1  Former Supreme Court judge Goh Joon Seng dies,...    3 months ago   \n",
       "2  Son of Mas Selamat: 10 years studying, teachin...   95 months ago   \n",
       "3  Ex-ISD chief: loyalty key lesson from Mas Sela...   92 months ago   \n",
       "4     Singapore's most wanted man nabbed in Malaysia  149 months ago   \n",
       "5  First Singaporean in an ISIS video: 3 question...   48 months ago   \n",
       "\n",
       "   year_of_birth                                        description  \\\n",
       "0             56  Mas Selamat Kastari (centre) leaving the Tanju...   \n",
       "1             60  ... set up to investigate the escape of Jemaah...   \n",
       "2             52  Masyhadi's father, former Jemaah Islamiah lead...   \n",
       "3             53  The senior civil servant under whose watch Mas...   \n",
       "4             48  Security experts said the capture of Mas Selam...   \n",
       "5             56  ... and captured Jemaah Islamiah (JI) leader M...   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://www.straitstimes.com/asia/se-asia/mas-...   \n",
       "1  https://www.straitstimes.com/singapore/former-...   \n",
       "2  https://www.straitstimes.com/singapore/son-of-...   \n",
       "3  https://www.straitstimes.com/singapore/ex-isd-...   \n",
       "4  https://www.reuters.com/article/us-singapore-m...   \n",
       "5  https://www.straitstimes.com/singapore/first-s...   \n",
       "\n",
       "                                                body  \\\n",
       "0  KUALA LUMPUR (THE STAR/ASIA NEWS NETWORK) - He...   \n",
       "1  SINGAPORE - Former Supreme Court judge Goh Joo...   \n",
       "2  The several hundred neighbours who attended th...   \n",
       "3  The senior civil servant under whose watch Mas...   \n",
       "4  SINGAPORE (Reuters) - The suspected leader of ...   \n",
       "5  1. Why feature a Singaporean?\\n\\nAlthough ISIS...   \n",
       "\n",
       "                                          names_list  confidence_score  \\\n",
       "0  {'Mas Selamat Kastari': 1, 'Stulang Laut': 1, ...          0.987366   \n",
       "1  {'Mas Selamat Kastari': 2, 'Goh Joon Seng': 1,...          0.957073   \n",
       "2  {'Mas Selamat Kastari': 2, 'Muhammad Hanif': 2...          0.983797   \n",
       "3  {'Mas Selamat Kastari': 2, 'Pang Kin Keong': 1...          0.987366   \n",
       "4  {'Mas Selamat Kastari': 3, 'Bali': 2, 'Wong Ka...          0.987366   \n",
       "5  {'Mas Selamat Kastari': 2, 'Megat Shahdan Abdu...          0.957073   \n",
       "\n",
       "  sentiment  \n",
       "0  positive  \n",
       "1  negative  \n",
       "2  negative  \n",
       "3   neutral  \n",
       "4  positive  \n",
       "5  negative  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Mas Selemat - Part of terrorist organisation, Jemaah Islamiyah (JI) \n",
    "\n",
    "demo(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individuals with no adverse news associated to them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test input: \n",
      "\n",
      "Name: Loh Hyun Jin Nelly\n",
      "Alias: None\n",
      "Year of Birth: 1997\n",
      "Month of Birth: None\n",
      "Day of Birth: None\n",
      "Gender: Male\n",
      "Nationality: Singapore\n",
      "Actual Name: None\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "No Articles found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-d76ac885cf50>\u001b[0m in \u001b[0;36mdemo\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m     \u001b[0;31m# Sentiment Analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentiment_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-d76ac885cf50>\u001b[0m in \u001b[0;36msentiment_model\u001b[0;34m(name_matched)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_matched\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No Articles found.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemExit\u001b[0m: No Articles found."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 7 Nelly Loh\n",
    "\n",
    "demo(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test input: \n",
      "\n",
      "Name: Tan Wee Beng\n",
      "Alias: None\n",
      "Year of Birth: 1977\n",
      "Month of Birth: None\n",
      "Day of Birth: None\n",
      "Gender: Male\n",
      "Nationality: Singapore\n",
      "Actual Name: Tan Wee Beng\n",
      "\n",
      "\n",
      "CPU times: user 11.6 s, sys: 318 ms, total: 11.9 s\n",
      "Wall time: 52 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>time</th>\n",
       "      <th>year_of_birth</th>\n",
       "      <th>description</th>\n",
       "      <th>link</th>\n",
       "      <th>body</th>\n",
       "      <th>names_list</th>\n",
       "      <th>confidence_score</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S'pore businessman wanted by FBI pleads guilty...</td>\n",
       "      <td>18 hours ago</td>\n",
       "      <td>0</td>\n",
       "      <td>Tan Wee Beng is on the FBI's most wanted list ...</td>\n",
       "      <td>https://www.straitstimes.com/singapore/courts-...</td>\n",
       "      <td>SINGAPORE - A Singaporean businessman, on the ...</td>\n",
       "      <td>{'Tan Wee Beng': 2, 'Tan': 12, 'Wee Tiong': 4,...</td>\n",
       "      <td>0.987366</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Singaporean on FBI's most wanted list charged ...</td>\n",
       "      <td>15 months ago</td>\n",
       "      <td>43</td>\n",
       "      <td>Tan Wee Beng is the managing director of Wee T...</td>\n",
       "      <td>https://www.channelnewsasia.com/singapore/sing...</td>\n",
       "      <td>SINGAPORE: A 43-year-old Singaporean managing ...</td>\n",
       "      <td>{'Tan Wee Beng': 2, 'Wee Tiong': 3, 'Tan': 5, ...</td>\n",
       "      <td>0.957073</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Singaporean MD on FBI most wanted list charged...</td>\n",
       "      <td>15 months ago</td>\n",
       "      <td>43</td>\n",
       "      <td>Tan Wee Beng, a 43-year old Singaporean managi...</td>\n",
       "      <td>https://www.manifoldtimes.com/news/singaporean...</td>\n",
       "      <td>Tan Wee Beng, a 43-year old Singaporean managi...</td>\n",
       "      <td>{'Tan Wee Beng': 4, 'Wee Tiong': 3, 'Tan': 4, ...</td>\n",
       "      <td>0.987366</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Singaporean accused of N. Korea dealings to ta...</td>\n",
       "      <td>35 months ago</td>\n",
       "      <td>41</td>\n",
       "      <td>SINGAPORE (AP) -- A Singaporean businessman fa...</td>\n",
       "      <td>https://mainichi.jp/english/articles/20181031/...</td>\n",
       "      <td>This wanted poster released by FBI shows Singa...</td>\n",
       "      <td>{'Wee Tiong': 6, 'Tan Wee Beng': 2, 'Singapore...</td>\n",
       "      <td>0.987366</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FBI Seeks Trader Accused of Violating North Ko...</td>\n",
       "      <td>35 months ago</td>\n",
       "      <td>41</td>\n",
       "      <td>Beng (aliases \"WB\", Wee Beng Tan, Marcus Tan, ...</td>\n",
       "      <td>https://www.maritime-executive.com/article/fbi...</td>\n",
       "      <td>FBI Seeks Trader Accused of Violating North Ko...</td>\n",
       "      <td>{'Beng': 6, 'Wee Beng Tan': 2, 'Marcus Tan': 2...</td>\n",
       "      <td>0.974873</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Top stories from The Straits Times on Friday, ...</td>\n",
       "      <td>35 months ago</td>\n",
       "      <td>41</td>\n",
       "      <td>US imposes North Korea-related sanctions on Si...</td>\n",
       "      <td>https://www.straitstimes.com/singapore/top-sto...</td>\n",
       "      <td>US imposes North Korea-related sanctions on Si...</td>\n",
       "      <td>{'Tan Wee Beng': 2, 'Steven Chong': 2, 'Davind...</td>\n",
       "      <td>0.957073</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Singapore commodity broker wanted by FBI charg...</td>\n",
       "      <td>15 months ago</td>\n",
       "      <td>43</td>\n",
       "      <td>Tan Wee Beng, managing director of trading com...</td>\n",
       "      <td>https://www.malaymail.com/news/singapore/2020/...</td>\n",
       "      <td>The North Korea flag flutters next to concerti...</td>\n",
       "      <td>{'Tan Wee Beng': 2, 'Wee Tiong': 3, 'Tan': 3}</td>\n",
       "      <td>0.957073</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Food stall attendant who stomped on man's face...</td>\n",
       "      <td>31 months ago</td>\n",
       "      <td>42</td>\n",
       "      <td>The older man was later taken to Tan Tock Seng...</td>\n",
       "      <td>https://stomp.straitstimes.com/singapore-seen/...</td>\n",
       "      <td>Shaffiq Alkhatib\\n\\nThe Straits Times\\n\\nFeb 1...</td>\n",
       "      <td>{'Wee': 7, 'Shaffiq Alkhatib': 1, 'Wee Boon': ...</td>\n",
       "      <td>0.987366</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title           time  \\\n",
       "0  S'pore businessman wanted by FBI pleads guilty...   18 hours ago   \n",
       "1  Singaporean on FBI's most wanted list charged ...  15 months ago   \n",
       "2  Singaporean MD on FBI most wanted list charged...  15 months ago   \n",
       "3  Singaporean accused of N. Korea dealings to ta...  35 months ago   \n",
       "4  FBI Seeks Trader Accused of Violating North Ko...  35 months ago   \n",
       "5  Top stories from The Straits Times on Friday, ...  35 months ago   \n",
       "6  Singapore commodity broker wanted by FBI charg...  15 months ago   \n",
       "7  Food stall attendant who stomped on man's face...  31 months ago   \n",
       "\n",
       "   year_of_birth                                        description  \\\n",
       "0              0  Tan Wee Beng is on the FBI's most wanted list ...   \n",
       "1             43  Tan Wee Beng is the managing director of Wee T...   \n",
       "2             43  Tan Wee Beng, a 43-year old Singaporean managi...   \n",
       "3             41  SINGAPORE (AP) -- A Singaporean businessman fa...   \n",
       "4             41  Beng (aliases \"WB\", Wee Beng Tan, Marcus Tan, ...   \n",
       "5             41  US imposes North Korea-related sanctions on Si...   \n",
       "6             43  Tan Wee Beng, managing director of trading com...   \n",
       "7             42  The older man was later taken to Tan Tock Seng...   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://www.straitstimes.com/singapore/courts-...   \n",
       "1  https://www.channelnewsasia.com/singapore/sing...   \n",
       "2  https://www.manifoldtimes.com/news/singaporean...   \n",
       "3  https://mainichi.jp/english/articles/20181031/...   \n",
       "4  https://www.maritime-executive.com/article/fbi...   \n",
       "5  https://www.straitstimes.com/singapore/top-sto...   \n",
       "6  https://www.malaymail.com/news/singapore/2020/...   \n",
       "7  https://stomp.straitstimes.com/singapore-seen/...   \n",
       "\n",
       "                                                body  \\\n",
       "0  SINGAPORE - A Singaporean businessman, on the ...   \n",
       "1  SINGAPORE: A 43-year-old Singaporean managing ...   \n",
       "2  Tan Wee Beng, a 43-year old Singaporean managi...   \n",
       "3  This wanted poster released by FBI shows Singa...   \n",
       "4  FBI Seeks Trader Accused of Violating North Ko...   \n",
       "5  US imposes North Korea-related sanctions on Si...   \n",
       "6  The North Korea flag flutters next to concerti...   \n",
       "7  Shaffiq Alkhatib\\n\\nThe Straits Times\\n\\nFeb 1...   \n",
       "\n",
       "                                          names_list  confidence_score  \\\n",
       "0  {'Tan Wee Beng': 2, 'Tan': 12, 'Wee Tiong': 4,...          0.987366   \n",
       "1  {'Tan Wee Beng': 2, 'Wee Tiong': 3, 'Tan': 5, ...          0.957073   \n",
       "2  {'Tan Wee Beng': 4, 'Wee Tiong': 3, 'Tan': 4, ...          0.987366   \n",
       "3  {'Wee Tiong': 6, 'Tan Wee Beng': 2, 'Singapore...          0.987366   \n",
       "4  {'Beng': 6, 'Wee Beng Tan': 2, 'Marcus Tan': 2...          0.974873   \n",
       "5  {'Tan Wee Beng': 2, 'Steven Chong': 2, 'Davind...          0.957073   \n",
       "6      {'Tan Wee Beng': 2, 'Wee Tiong': 3, 'Tan': 3}          0.957073   \n",
       "7  {'Wee': 7, 'Shaffiq Alkhatib': 1, 'Wee Boon': ...          0.987366   \n",
       "\n",
       "  sentiment  \n",
       "0  positive  \n",
       "1  negative  \n",
       "2  positive  \n",
       "3   neutral  \n",
       "4  negative  \n",
       "5  positive  \n",
       "6  positive  \n",
       "7  negative  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "demo(0)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a41f48461941a5aefc82610e94371dafd9500cffa630c3ca9566e477af78c3ed"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
